import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, callbacks
from tensorflow.keras.applications import EfficientNetB0, ResNet50, DenseNet121,MobileNetV3Small,EfficientNetV2B0
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import load_img, img_to_array
from tensorflow.python.profiler.model_analyzer import profile
from tensorflow.python.profiler.option_builder import ProfileOptionBuilder
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, classification_report
import os
import time

# 2. 全局设置混合精度策略
tf.keras.mixed_precision.set_global_policy('mixed_float16')

# 3. 路径与参数
train_dir = "/root/.cache/kagglehub/datasets/tomgzg/split-tomato-data-4-224x224/versions/1/train"
val_dir = "/root/.cache/kagglehub/datasets/tomgzg/split-tomato-data-4-224x224/versions/1/val"
test_dir = "/root/.cache/kagglehub/datasets/tomgzg/split-tomato-data-4-224x224/versions/1/test"
input_shape = (224, 224, 3)
num_classes = 10
batch_size = 32
epochs = 100

# 5. 自定义模块
class DynamicChannelAttention(layers.Layer):
    def __init__(self, reduction_ratio=8):
        super().__init__()
        self.reduction_ratio = reduction_ratio

    def build(self, input_shape):
        self.global_avg_pool = layers.GlobalAveragePooling2D()
        self.fc1 = layers.Dense(self.reduction_ratio, activation='swish', kernel_regularizer=tf.keras.regularizers.l2(1e-4))
        self.fc2 = layers.Dense(input_shape[-1], activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(1e-4))

    def call(self, inputs):
        avg_pool = self.global_avg_pool(inputs)
        attention = self.fc1(avg_pool)
        attention = self.fc2(attention)
        attention = layers.Reshape((1, 1, -1))(attention)
        return inputs * attention

class SeparableDilatedConvBlock(layers.Layer):
    def __init__(self, filters, dilation_rate):
        super().__init__()
        self.conv1 = layers.SeparableConv2D(filters, (3, 3), dilation_rate=dilation_rate, padding='same', activation='swish')
        self.conv2 = layers.Conv2D(filters, (1, 1), padding='same', activation='swish')

    def call(self, inputs):
        x = self.conv1(inputs)
        return self.conv2(x)

class CANBlock(layers.Layer):
    def __init__(self, reduction_ratio=8):
        super().__init__()
        self.reduction_ratio = reduction_ratio

    def build(self, input_shape):
        self.conv1 = layers.Conv2D(input_shape[-1] // self.reduction_ratio, kernel_size=(3, 3), padding='same', activation='swish')
        self.conv2 = layers.Conv2D(input_shape[-1], kernel_size=(1, 1), padding='same', activation='sigmoid')

    def call(self, inputs):
        x = self.conv1(inputs)
        attention_map = self.conv2(x)
        return inputs * attention_map

def DCA_SDC_CAN_EfficientNetB0(input_shape, num_classes):
    base_model = EfficientNetB0(include_top=False, input_shape=input_shape, weights='imagenet')
    base_model.trainable = True  # 微调

    model_input = layers.Input(shape=input_shape)
    x = base_model(model_input)

    x = DynamicChannelAttention()(x)
    x = SeparableDilatedConvBlock(64, dilation_rate=(2, 2))(x)
    x = CANBlock()(x)
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(1024, activation='swish')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Dropout(0.5)(x)
    output = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)
    model = models.Model(inputs=model_input, outputs=output)
    return model

def create_original_efficientnet(input_shape, num_classes):
    base_model = EfficientNetB0(include_top=False, input_shape=input_shape, weights='imagenet')
    base_model.trainable = True
    inputs = layers.Input(shape=input_shape)
    x = base_model(inputs)
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(1024, activation='swish')(x)
    x = layers.Dropout(0.5)(x)
    outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)
    model = models.Model(inputs, outputs)
    return model

def create_resnet50(input_shape, num_classes):
    base_model = ResNet50(include_top=False, input_shape=input_shape, weights='imagenet')
    base_model.trainable = True
    inputs = layers.Input(shape=input_shape)
    x = base_model(inputs)
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(1024, activation='swish')(x)
    x = layers.Dropout(0.5)(x)
    outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)
    model = models.Model(inputs, outputs)
    return model

def create_densenet121(input_shape, num_classes):
    base_model = DenseNet121(include_top=False, input_shape=input_shape, weights='imagenet')
    base_model.trainable = True
    inputs = layers.Input(shape=input_shape)
    x = base_model(inputs)
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(1024, activation='swish')(x)
    x = layers.Dropout(0.5)(x)
    outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)
    model = models.Model(inputs, outputs)
    return model

def create_efficientnetv2b0(input_shape, num_classes):
    base_model = EfficientNetV2B0(include_top=False, input_shape=input_shape, weights='imagenet')
    base_model.trainable = True  # 支持微调
    inputs = layers.Input(shape=input_shape)
    x = base_model(inputs)
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(1024, activation='swish')(x)
    x = layers.Dropout(0.5)(x)
    outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)
    model = models.Model(inputs, outputs)
    return model

def create_mobilenetv3lite(input_shape, num_classes):
    base_model = MobileNetV3Small(include_top=False, input_shape=input_shape, weights='imagenet')
    base_model.trainable = True
    inputs = layers.Input(shape=input_shape)
    x = base_model(inputs)
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(1024, activation='swish')(x)
    x = layers.Dropout(0.5)(x)
    outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)
    model = models.Model(inputs, outputs)
    return model

# 7. 模型配置
models_config = {
    'DCA_SDC_CAN_EfficientNetB0': lambda: DCA_SDC_CAN_EfficientNetB0(input_shape, num_classes),
    'Original EfficientNetB0': lambda: create_original_efficientnet(input_shape, num_classes),
    'EfficientNetV2B0': lambda: create_efficientnetv2b0(input_shape, num_classes), 
    'MobileNetV3Small': lambda: create_mobilenetv3lite(input_shape, num_classes),
    'ResNet50': lambda: create_resnet50(input_shape, num_classes),
    'DenseNet121': lambda: create_densenet121(input_shape, num_classes)
}
#数据预处理
train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_directory(train_dir, target_size=input_shape[:2], batch_size=batch_size, class_mode='categorical')
val_generator = val_datagen.flow_from_directory(val_dir, target_size=input_shape[:2], batch_size=batch_size, class_mode='categorical')
test_generator = test_datagen.flow_from_directory(test_dir, target_size=input_shape[:2], batch_size=batch_size, class_mode='categorical', shuffle=False)

reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.4, min_lr=1e-6, verbose=1)

# 1. 文件名集合（用于overlap检查）
def get_all_filenames(folder):
    all_files = set()
    for root, dirs, files in os.walk(folder):
        for file in files:
            all_files.add(file)
    return all_files

train_files = get_all_filenames(train_dir)
val_files = get_all_filenames(val_dir)
test_files = get_all_filenames(test_dir)

def plot_confusion_matrix(y_true, y_pred, class_indices, model_name):
    class_names = [k for k, v in sorted(class_indices.items(), key=lambda x: x[1])]
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names)
    plt.title(f'{model_name} Confusion Matrix')
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.xticks(rotation=90)
    plt.yticks(rotation=0)
    plt.tight_layout()
    plt.show()

# 2. 训练和评估主流程
histories = {}
results = {}
for model_name, model_fn in models_config.items():
    print(f"\nTraining model: {model_name}")
    model = model_fn()
    model.summary()
    model.compile(optimizer=tf.keras.optimizers.Adam(),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    history = model.fit(
        train_generator,
        epochs=epochs,
        validation_data=val_generator,
        callbacks=[reduce_lr]
    )
    histories[model_name] = history

    # 评估
    print(f"Evaluating {model_name}...")
    test_loss, test_acc = model.evaluate(test_generator, verbose=2)
    y_true = test_generator.classes
    y_pred = np.argmax(model.predict(test_generator), axis=-1)
    precision = precision_score(y_true, y_pred, average='macro', zero_division=0)
    recall = recall_score(y_true, y_pred, average='macro', zero_division=0)
    f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)
    #flops计算
    input_signature = [tf.TensorSpec([1, 224, 224, 3], tf.float32)]
    graph = tf.function(model).get_concrete_function(*input_signature)
    opts = ProfileOptionBuilder.float_operation()
    opts['output'] = 'none'
    flops = profile(graph.graph, options=opts).total_float_ops
    flops_g = flops / 1e9
    # 推理时间 (ms)
    start_time = time.time()
    # 进行多次推理，取平均时间
    n_iterations = 100  # 推理次数
    for _ in range(n_iterations):
        model.predict(test_generator, verbose=0)
    inference_time = (time.time() - start_time) / n_iterations  # 转换为秒
    results[model_name] = {
        'model_name': model_name,
        'accuracy': f"{test_acc * 100:.2f}%",
        'precision': f"{precision * 100:.2f}%",
        'recall': f"{recall * 100:.2f}%",
        'f1_score': f"{f1 * 100:.2f}%",
        'flops': flops_g,
        'params': model.count_params(),
        'inference_time': f"{inference_time:.2f}s",
    }
    # 创建结果表格
    results_df = pd.DataFrame(list(results.values()))
    display(results_df)
    plot_confusion_matrix(y_true, y_pred, test_generator.class_indices, model_name)
    print(classification_report(y_true, y_pred, target_names=[k for k, v in sorted(test_generator.class_indices.items(), key=lambda x: x[1])], zero_division=0))  
    tf.keras.backend.clear_session()

# 3. overlap 检查
print("Train class indices:", train_generator.class_indices)
print("Val class indices:", val_generator.class_indices)
print("Test class indices:", test_generator.class_indices)
print("Train & Val overlap:", len(train_files & val_files))
print("Train & Test overlap:", len(train_files & test_files))
print("Val & Test overlap:", len(val_files & test_files))

# 4. 绘制曲线
def plot_accuracy_comparison(histories):
    plt.figure(figsize=(10, 6))
    for model_name, history in histories.items():
        plt.plot(history.history['val_accuracy'], label=f'{model_name} Val')
    plt.xlabel('Epoch')
    plt.ylabel('Validation Accuracy')
    plt.legend()
    plt.title('Validation Accuracy Comparison')
    plt.grid(True)
    plt.show()

def plot_loss_comparison(histories):
    plt.figure(figsize=(10, 6))
    for model_name, history in histories.items():
        plt.plot(history.history['val_loss'], label=f'{model_name} Val')
    plt.xlabel('Epoch')
    plt.ylabel('Validation Loss')
    plt.legend()
    plt.title('Validation Loss Comparison')
    plt.grid(True)
    plt.show()

plot_accuracy_comparison(histories)
plot_loss_comparison(histories)

# 5. 汇总结果
results_df = pd.DataFrame(list(results.values()))
display(results_df)
